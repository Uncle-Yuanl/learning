{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            }
        },
        {
            "name": "Transformers",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/torch/bin/python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
            }
        },
        {
            "name": "LlaMa3",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/llamacpp/bin/python",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "CUDA_VISIBLE_DEVICES": "0"
            }
        },
        {
            "name": "StackLlaMa SFT",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/llamacpp/bin/python",
            "request": "launch",
            "program": "${workspaceFolder}/AIGC/Lllama3/trl_stackllama.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://localhost:7890",
                "https_proxy": "http://localhost:7890",
                "WANDB_PROJECT": "StackLlaMa",
                "WANDB_LOG_MODEL": "false",
                "WANDB_WATCH": "false",
                "WANDB_RUN_ID": "yo1c1p14",
                "WANDB_RESUME": "allow",
                "RANK": "0",
                "WORLD_SIZE": "1"
            },
            "args": [
                "sft",
                "--num_workers", "2",
                "--bf16",
                "--batch_size", "6",
                "--gradient_accumulation_steps", "32",
                "--gradient_checkpointing"
            ]
        },
        {
            "name": "StackLlaMa Merge",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/llamacpp/bin/python",
            "request": "launch",
            "program": "${workspaceFolder}/AIGC/Lllama3/trl_stackllama.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                // "NCCL_IB_DISABLE": "1",
                // "NCCL_P2P_DISABLE": "1",
                "CUDA_VISIBLE_DEVICES": "0",
                // "RANK": "0",
                // "WORLD_SIZE": "1"
            },
            "args": [
                "merge",
                // sft se model
                // "--adapter_model_name", "/media/data/LLMS/StackLlama/checkpoints/final_checkpoint",
                // "--base_model_name", "/media/data/LLMS/Llama3-hf",
                // "--output_name", "/media/data/LLMS/StackLlama/llama-se"
                // rm se model
                "--adapter_model_name", "/media/data/LLMS/StackLlama/llama-se_peft_stack-exchange-paired_rmts__100000_2e-05/last_checkpoint",
                "--base_model_name", "/media/data/LLMS/StackLlama/llama-se",
                "--output_name", "/media/data/LLMS/StackLlama/llama-rm"
            ]
        },
        {
            "name": "StackLlaMa RM",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/llamacpp/bin/python",
            "request": "launch",
            "program": "${workspaceFolder}/AIGC/Lllama3/trl_stackllama.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://localhost:7890",
                "https_proxy": "http://localhost:7890",
                "WANDB_PROJECT": "StackLlaMa RM",
                "WANDB_LOG_MODEL": "false",
                "WANDB_WATCH": "false",
                // "WANDB_RUN_ID": "yo1c1p14",
                // "WANDB_RESUME": "must",
                "RANK": "0",
                "WORLD_SIZE": "1"
            },
            "args": [
                "rm",
                "--model_path",
                "/media/data/LLMS/StackLlama/llama-se",
                "--subset", "data/reward",
                "--num_workers", "8",
                "--bf16",
                "--batch_size", "6",
                "--learning_rate", "2e-5",
                "--weight_decay", "0.001",
                "--eval_freq", "500",
                "--save_freq", "500",
                "--log_freq", "10",
                "--gradient_accumulation_steps", "32",
                "--gradient_checkpointing",
                "--lr_scheduler_type", "linear"
            ]
        },
        {
            "name": "StackLlaMa RLHF",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/llamacpp/bin/python",
            "request": "launch",
            "program": "${workspaceFolder}/AIGC/Lllama3/trl_stackllama.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://localhost:7890",
                "https_proxy": "http://localhost:7890",
                "WANDB_PROJECT": "StackLlaMa RLHF",
                "WANDB_LOG_MODEL": "false",
                "WANDB_WATCH": "false",
                // "WANDB_RUN_ID": "a1vk4gtf",
                // "WANDB_RESUME": "must",
                "RANK": "0",
                "WORLD_SIZE": "1"
            },
            "args": [
                "rlhf",
                "--model_path",
                "/media/data/LLMS/StackLlama/llama-se",
                "--reward_model_name",
                "/media/data/LLMS/StackLlama/llama-rm",
                "--output_dir",
                "/media/data/LLMS/StackLlama/llama-rl/runs",
                "--subset", "data/rl",
                "--steps",
                "2000",
                "--num_workers", "4",
                "--batch_size", "6",
                "--learning_rate", "1.41e-5",
                "--gradient_accumulation_steps", "6",
                "--log_with", "wandb"
            ]
        },
        {
            "name": "Multimodal",
            "type": "debugpy",
            "python": "/home/yhao/.conda/envs/beit3/bin/python",
            "request": "launch",
            "program": "${workspaceFolder}/DL/multimodal/beit3.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "cwd": "${workspaceFolder}",
            "env": {
                "NCCL_IB_DISABLE": "1",
                "NCCL_P2P_DISABLE": "1",
                "PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION": "python",
                "CUDA_VISIBLE_DEVICES": "0"
            }
        },
        {
            "name": "FastAPI (Uvicorn)",
            "type": "debugpy",
            "request": "launch",
            "module": "uvicorn",
            "args": [
                "AIGC.local.proxy:app",            // main.py 里实例是 app
                "--host", "127.0.0.1",
                "--port", "8000",
                "--reload"             // 允许热重载
            ],
            "cwd": "${workspaceFolder}",
            "jinja": true,
            "justMyCode": true,
            "console": "integratedTerminal"
        }
    ]
}